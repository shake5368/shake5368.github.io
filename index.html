<!DOCTYPE html>
<html>
<head>
  <title>即時語音問答</title>
  <style>
    #chatbox {
      display: flex;
      flex-direction: column;
      height: 300px;
      overflow-y: scroll;
      border: 1px solid #ccc;
      padding: 10px;
    }
    .message {
      margin-bottom: 10px;
    }
    .user-message {
      text-align: right;
    }
    .bot-message {
      text-align: left;
    }
    .recording-indicator {
      width: 10px;
      height: 10px;
      background-color: red;
      border-radius: 50%;
      display: inline-block;
      margin-left: 5px;
      animation: blink 1s infinite;
    }
    @keyframes blink {
      50% {
        background-color: transparent;
      }
    }
  </style>
</head>
<body>
  <div id="chatbox"></div>
  <button id="startBtn">開始對話</button>
  <button id="stopBtn" disabled>結束對話</button>
  <span id="recordingIndicator" class="recording-indicator" style="display:none;"></span>

  <script>
    const chatbox = document.getElementById('chatbox');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const recordingIndicator = document.getElementById('recordingIndicator');

    let mediaRecorder;
    let isRecording = false;

    startBtn.addEventListener('click', async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      startRecording();

      startBtn.disabled = true;
      stopBtn.disabled = false;
    });

    stopBtn.addEventListener('click', () => {
      stopRecording();
      startBtn.disabled = false;
      stopBtn.disabled = true;
    });

    function startRecording() {
      isRecording = true;
      recordingIndicator.style.display = 'inline-block';
      const chunks = [];

      mediaRecorder.ondataavailable = e => chunks.push(e.data);

      mediaRecorder.onstop = async () => {
        recordingIndicator.style.display = 'none';
        const blob = new Blob(chunks, { type: 'audio/webm; codecs=opus' });
        const reader = new FileReader();
        reader.onloadend = async () => {
          const base64Audio = reader.result;
          const message = await processAudio(base64Audio);
          displayMessage('user', base64Audio, message);
          if (isRecording) {
            startRecording(); // 继续录音
          }
        };
        reader.readAsDataURL(blob);
      };

      mediaRecorder.start();
      setTimeout(() => mediaRecorder.stop(), 4000); // 4 秒后停止录音
    }

    function stopRecording() {
      isRecording = false;
      mediaRecorder.stop();
    }

    function displayMessage(role, audioData, text = '') {
      const messageDiv = document.createElement('div');
      messageDiv.classList.add('message', `${role}-message`);

      const audio = document.createElement('audio');
      audio.controls = true;
      audio.src = audioData;
      messageDiv.appendChild(audio);

      if (text) {
        const textSpan = document.createElement('span');
        textSpan.textContent = text;
        messageDiv.appendChild(textSpan);
      }

      chatbox.appendChild(messageDiv);
      chatbox.scrollTop = chatbox.scrollHeight; // 自動滾動到底部
    }

    async function processAudio(base64Audio) {
      // 在这里添加你的语音处理逻辑，例如发送到后端 API 进行语音转文字
      // 然后返回处理后的文字信息
      // 这里只是一个示例，返回模拟的语音转文字结果
      return new Promise(resolve => {
        setTimeout(() => {
          resolve('（这里是语音转文字的示例结果）');
        }, 1000); // 模拟处理时间
      });
    }
  </script>
</body>
</html>
